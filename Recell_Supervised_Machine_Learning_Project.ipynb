{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkNoble-1/portfolio/blob/main/Recell_Supervised_Machine_Learning_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2r5o8SR4rqH"
      },
      "source": [
        "# Supervised Learning - Foundations Project: ReCell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SntBY974rqJ"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA_GXJwuhmVz"
      },
      "source": [
        "### Business Context\n",
        "\n",
        "Buying and selling used phones and tablets used to be something that happened on a handful of online marketplace sites. But the used and refurbished device market has grown considerably over the past decade, and a new IDC (International Data Corporation) forecast predicts that the used phone market would be worth \\\\$52.7bn by 2023 with a compound annual growth rate (CAGR) of 13.6% from 2018 to 2023. This growth can be attributed to an uptick in demand for used phones and tablets that offer considerable savings compared with new models.\n",
        "\n",
        "Refurbished and used devices continue to provide cost-effective alternatives to both consumers and businesses that are looking to save money when purchasing one. There are plenty of other benefits associated with the used device market. Used and refurbished devices can be sold with warranties and can also be insured with proof of purchase. Third-party vendors/platforms, such as Verizon, Amazon, etc., provide attractive offers to customers for refurbished devices. Maximizing the longevity of devices through second-hand trade also reduces their environmental impact and helps in recycling and reducing waste. The impact of the COVID-19 outbreak may further boost this segment as consumers cut back on discretionary spending and buy phones and tablets only for immediate needs.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "The rising potential of this comparatively under-the-radar market fuels the need for an ML-based solution to develop a dynamic pricing strategy for used and refurbished devices. ReCell, a startup aiming to tap the potential in this market, has hired you as a data scientist. They want you to analyze the data provided and build a linear regression model to predict the price of a used phone/tablet and identify factors that significantly influence it.\n",
        "\n",
        "\n",
        "### Data Description\n",
        "\n",
        "The data contains the different attributes of used/refurbished phones and tablets. The data was collected in the year 2021. The detailed data dictionary is given below.\n",
        "\n",
        "\n",
        "- brand_name: Name of manufacturing brand\n",
        "- os: OS on which the device runs\n",
        "- screen_size: Size of the screen in cm\n",
        "- 4g: Whether 4G is available or not\n",
        "- 5g: Whether 5G is available or not\n",
        "- main_camera_mp: Resolution of the rear camera in megapixels\n",
        "- selfie_camera_mp: Resolution of the front camera in megapixels\n",
        "- int_memory: Amount of internal memory (ROM) in GB\n",
        "- ram: Amount of RAM in GB\n",
        "- battery: Energy capacity of the device battery in mAh\n",
        "- weight: Weight of the device in grams\n",
        "- release_year: Year when the device model was released\n",
        "- days_used: Number of days the used/refurbished device has been used\n",
        "- normalized_new_price: Normalized price of a new device of the same model in euros\n",
        "- normalized_used_price: Normalized price of the used/refurbished device in euros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_-uuGqH-qTt"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeF8YaNKDPyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f525195-b59b-47cd-a7be-05549a25c1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/9.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/9.6 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.10 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.0 requires matplotlib>=3.8.0, but you have matplotlib 3.7.1 which is incompatible.\n",
            "plotnine 0.14.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Installing the libraries with the specified version.\n",
        "# uncomment and run the following line if Google Colab is being used\n",
        "!pip install scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.3 -q --user"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the libraries with the specified version.\n",
        "# uncomment and run the following lines if Jupyter Notebook is being used\n",
        "# !pip install scikit-learn==1.2.2 seaborn==0.11.1 matplotlib==3.3.4 numpy==1.24.3 pandas==1.5.2 -q --user"
      ],
      "metadata": {
        "id": "00QmL7SOSd6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Libraries to help with reading and manipulating data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "\n",
        "# split the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to build linear regression_model using statsmodels\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# to build linear regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# to check model performance\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# to compute VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ],
      "metadata": {
        "id": "uLXU5tMxN9-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Python Course/ML\n",
        "!jupyter nbconvert SLF_Project_LearnerNotebook_FullCode.ipynb--to html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpqqC7wQ5kmZ",
        "outputId": "c5966c1b-234a-4ec1-dc5e-15825d0107df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Python Course/ML'\n",
            "/content\n",
            "[NbConvertApp] WARNING | pattern 'SLF_Project_LearnerNotebook_FullCode.ipynb--to' matched no files\n",
            "[NbConvertApp] WARNING | pattern 'html' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: *After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the start again.*"
      ],
      "metadata": {
        "id": "tcrfa8CUlSot"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FhTnNFx_lWxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxhpZv9y-qTw"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJwX9wuc4rqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03bd7aa-dadd-4f75-8921-127e90397c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "INN = pd.read_csv('/content/drive/MyDrive/Python Course/ML/INNHotelsGroup.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvpMDcaaMKtI"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Observations\n",
        "- Sanity checks"
      ],
      "metadata": {
        "id": "tIiCRwqZ54_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First and Last 5 rows of the dataset"
      ],
      "metadata": {
        "id": "Ae0if6KuQu7x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01hJQ7EfMKtK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "83489106-bae8-4ac3-b481-8a4749394f8d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'UDD' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ce12c6186685>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#first 5 rows of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'UDD' is not defined"
          ]
        }
      ],
      "source": [
        "UDD.head() #first 5 rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UDD.tail() #last 5 rows of the dataset"
      ],
      "metadata": {
        "id": "e_M7cAILQ_PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- The data looks as expected"
      ],
      "metadata": {
        "id": "kb_YwjcyQjp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shape of the dataset"
      ],
      "metadata": {
        "id": "KGPH966vRFln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UDD.shape #shape of the data"
      ],
      "metadata": {
        "id": "d6UYJDQxRM9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- there are 3454 rows and 15 columns in the dataset"
      ],
      "metadata": {
        "id": "7UMEaxsIRQJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical summary of the data"
      ],
      "metadata": {
        "id": "vyfjiWMYTxsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UDD.describe(include=[np.number]) #statistical summary of the numerical data"
      ],
      "metadata": {
        "id": "2H6U6F_2T1EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UDD.describe(include=[object]) #statistical summary of the categorical data"
      ],
      "metadata": {
        "id": "vbuV0JmKUQMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- Based on the count, there seems to be missing data for some numerical columns\n",
        "- release_year would make more sense as a categorical variable\n",
        "- We will be comparing 43 unique brands with only 4 different types of OS"
      ],
      "metadata": {
        "id": "n8fEZLFEUbcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datatype Information & Missing Data"
      ],
      "metadata": {
        "id": "05LWTkEwRagv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UDD.duplicated().sum() #checking for duplicates"
      ],
      "metadata": {
        "id": "55VUyTrTWxhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UDD.info() #datatype information"
      ],
      "metadata": {
        "id": "quDpul6XRhYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UDD.isnull().sum() #missing data"
      ],
      "metadata": {
        "id": "jtlTc6eOWVK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- there is no duplicated data in the dataset\n",
        "\n",
        "- The datatypes are as expected, implying that there is no missing data in numeric columns\n",
        "\n",
        "- The following columns contain missing data:\n",
        " -  5   main_camera_mp: 179 missing         \n",
        " - 6   selfie_camera_mp: 2 missing       \n",
        " - 7   int_memory:       4 missing   \n",
        " - 8   ram:              4 missing     \n",
        " -  9   battery:         6 missing     \n",
        " - 10  weight            7 missing    "
      ],
      "metadata": {
        "id": "Tzm8SUpcVMo_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__7ciGcIDPyk"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "udd_with_missing_values = UDD.copy() #making a copy of the dataset"
      ],
      "metadata": {
        "id": "t0DojmPCsrO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What does the distribution of normalized used device prices look like?"
      ],
      "metadata": {
        "id": "F6lrLPGCtun-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "udd_with_missing_values.hist(column='normalized_used_price', bins=30)"
      ],
      "metadata": {
        "id": "tAYtpyCbvSFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "udd_with_missing_values.hist(column='normalized_new_price', bins=30)"
      ],
      "metadata": {
        "id": "KyhI9DOXvvuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- the distribution of normalized used prices is approximately normal with a slight left skew\n",
        "- the distribution of normalized new prices is approximately normal with a slight right skew"
      ],
      "metadata": {
        "id": "fA1bn_Q8v49x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What percentage of the used device market is dominated by Android devices?"
      ],
      "metadata": {
        "id": "GDhrW5F3tzE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=udd_with_missing_values['os'])"
      ],
      "metadata": {
        "id": "KeO5wZ327aJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Android_count = udd_with_missing_values['os'].value_counts()['Android'] #count of Android devices in the dataset\n",
        "Total_count = udd_with_missing_values['os'].value_counts().sum()        #total count of devices in the dataset\n",
        "Android_domination = (Android_count/Total_count)*100                    #percentage of Android devices in the dataset\n",
        "print(f'The percentage of the used device market that is dominated by Android devices is {Android_domination:.2f}%')"
      ],
      "metadata": {
        "id": "s3SE8-0h6lwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- The percentage of the used device market that is dominated by Android devices is 93.05%"
      ],
      "metadata": {
        "id": "of9vX9ead4z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How does the amount of RAM vary with the brand?"
      ],
      "metadata": {
        "id": "93nR8KqUtziK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brand_name_alphabetized = sorted(udd_with_missing_values['brand_name'].unique()) #list of unique brands in alphabetical order\n",
        "plt.figure(figsize=(20,5))\n",
        "sns.boxplot(x=udd_with_missing_values['brand_name'], y=udd_with_missing_values['ram'], order = brand_name_alphabetized) # box plot of ram by brand\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YhUVG5_oeCwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- there are many outliers in the RAM offered by each brand\n",
        "- all brands offer at least 4gb of RAM on one or more of the devices they sell\n",
        "- 75% OnePlus devices have between 4 and 8 gb of RAM and 25% have between 8 and 12 gb of RAM, suggesting that OnePlus devices offer more RAM on average than other devices"
      ],
      "metadata": {
        "id": "d5KlUifPfDnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How does the weight vary for phones and tablets offering large batteries (more than 4500 mAh)?"
      ],
      "metadata": {
        "id": "yasG9p-Ltzuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 4500\n",
        "large_battery_devices = udd_with_missing_values[(udd_with_missing_values['battery'] > threshold)]  #filter for devices with large batteries"
      ],
      "metadata": {
        "id": "UVUDfB27lP-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_battery_devices.shape"
      ],
      "metadata": {
        "id": "znuUcVr0lRR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 4500                                                                                                       #threshold for large batteries\n",
        "plt.figure(figsize=(20,5))\n",
        "sns.boxplot(x=large_battery_devices['brand_name'], y=large_battery_devices['weight'], order = brand_name_alphabetized) #boxplot of weight vs brand name for large battery devices\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h0hc5y-vhjAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- large battery Samsung devices vary the most on weight\n",
        "- many brands offer devices with large batteries but relatively low weight\n",
        "- Blackberry, Celkon, Coolpad, Karbonn, Lava, Meizu, Microsoft, OnePlus and Xolo do not offer devices with large batteries\n",
        "- for many brands 75% of their devices weigh below 500 grams"
      ],
      "metadata": {
        "id": "fcyecKkVjRKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How many phones and tablets are available across different brands with a screen size larger than 6 inches?"
      ],
      "metadata": {
        "id": "qGu1-R8wt0BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 15.24                                                                                    #6 inches = 15.24 cm\n",
        "large_screen_devices = udd_with_missing_values[(udd_with_missing_values['screen_size'] > threshold)] #filter for devices with large screens"
      ],
      "metadata": {
        "id": "lEFmfcnfntcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_screen_devices.shape"
      ],
      "metadata": {
        "id": "8abtwXLQn0zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "sns.countplot(x=large_screen_devices['brand_name'], order = brand_name_alphabetized) #countplot of large screen devices by brand\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E01os_iwpLhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- 1099 devices across different brands are available with a screen size larger than 6 inches\n",
        "- Huawei offers the most devices with a screen size larger than 6 inches, followed by Samsung\n",
        "- BlackBerry, Celkon and Lava offer no devices with a screen size larger than 6 inches"
      ],
      "metadata": {
        "id": "sBZfFYqAphLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is the distribution of devices offering greater than 8MP selfie cameras across brands?"
      ],
      "metadata": {
        "id": "MR8_UCZQvIuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 8                                                                                               #threshold for high MP selfie cameras\n",
        "high_mp_selfie_devices = udd_with_missing_values[(udd_with_missing_values['selfie_camera_mp'] > threshold)] #filter for devices with high MP selfie cameras"
      ],
      "metadata": {
        "id": "KMuCjmxDp6cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "sns.countplot(x=high_mp_selfie_devices['brand_name'], order = brand_name_alphabetized) #countplot of high MP selfie devices by brand\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WrvF9-HYqQgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- Huawei offers the most devices with a greater than 8MP selfie camera, followed by Vivo and Oppo\n",
        "- Alcatel, Celkon, Google, Karbonn, Lava, Microsoft, Spice, and Xolo do not offer devices with a larger than 8MP selfie camera"
      ],
      "metadata": {
        "id": "9CqkpsrPqtO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Which attributes are highly correlated with the normalized price of a used device?"
      ],
      "metadata": {
        "id": "vfwZ-qsPt0Ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "heatmap_columns = udd_with_missing_values.select_dtypes(include=[np.number]).columns #list of numerical columns\n",
        "heatmap_columns = heatmap_columns.drop('release_year')                               #dropping release year as this is more of a categorical variable\n",
        "sns.heatmap(data=udd_with_missing_values[heatmap_columns].corr(), annot=True, vmin=-1, vmax=1);       #heatmap of numerical values\n"
      ],
      "metadata": {
        "id": "FT_8mRQLrIKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- normalized used price is highly correlated with normalized new price, and is somewhat correlated (greater than .6) with battery, selfie camera mp and screen size, suggesting the new price of a phone has a high impact on the used price\n",
        "\n",
        "- battery and weight are highly correlated with screen size suggesting that the larger the screen size, the battery and / or weight will similarly be larger\n",
        "\n",
        "- the strongest negative correlation is between selfie camera mp and days used"
      ],
      "metadata": {
        "id": "DQ6pJbvv4qL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- EDA is an important part of any project involving data.\n",
        "- It is important to investigate and understand the data better before building a model with it.\n",
        "- A few questions have been mentioned below which will help you approach the analysis in the right manner and generate insights from the data.\n",
        "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
      ],
      "metadata": {
        "id": "3bGVKmh75ri8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEyqzdJBb0jU"
      },
      "source": [
        "**Questions**:\n",
        "\n",
        "1. What does the distribution of normalized used device prices look like?\n",
        "2. What percentage of the used device market is dominated by Android devices?\n",
        "3. The amount of RAM is important for the smooth functioning of a device. How does the amount of RAM vary with the brand?\n",
        "4. A large battery often increases a device's weight, making it feel uncomfortable in the hands. How does the weight vary for phones and tablets offering large batteries (more than 4500 mAh)?\n",
        "5. Bigger screens are desirable for entertainment purposes as they offer a better viewing experience. How many phones and tablets are available across different brands with a screen size larger than 6 inches?\n",
        "6. A lot of devices nowadays offer great selfie cameras, allowing us to capture our favorite moments with loved ones. What is the distribution of devices offering greater than 8MP selfie cameras across brands?\n",
        "7. Which attributes are highly correlated with the normalized price of a used device?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVn5toJ7MKte"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Missing value treatment\n",
        "- Feature engineering (if needed)\n",
        "- Outlier detection and treatment (if needed)\n",
        "- Preparing data for modeling\n",
        "- Any other preprocessing steps (if needed)"
      ],
      "metadata": {
        "id": "YcceZiPd5vGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Value Treatment"
      ],
      "metadata": {
        "id": "DRFkVhrU7ys7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "udd = UDD.copy() #making a copy of the dataset"
      ],
      "metadata": {
        "id": "8yPnxi9msgj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUi6E9EUMKth"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=udd['main_camera_mp']) #checking for outliers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "udd.isnull().sum()"
      ],
      "metadata": {
        "id": "oeWh9ZsWgI_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "median_main_camera_mp_by_year = udd.groupby(['release_year'])['main_camera_mp'].transform('median')              #group the main_camera_mp for each release year\n",
        "median_selfie_camera_mp_by_year = udd.groupby(['release_year'])['selfie_camera_mp'].transform('median')          #group the selfie_camera_mp for each release year\n",
        "median_int_memory_by_year = udd.groupby(['release_year'])['int_memory'].transform('median')                      #group the int_memory for each release year\n",
        "median_ram_by_year = udd.groupby(['release_year'])['ram'].transform('median')                                    #group the ram for each release year\n",
        "median_battery_by_year = udd.groupby(['release_year'])['battery'].transform('median')                            #group the battery for each release year\n",
        "median_weight_by_year = udd.groupby(['release_year'])['weight'].transform('median')                              #group the weight for each release year"
      ],
      "metadata": {
        "id": "PCNuV9tznhlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "udd['main_camera_mp'] = udd['main_camera_mp'].fillna(median_main_camera_mp_by_year)       # fill missing values in main_camera_mp with the median main_camera_mp for its respective release year\n",
        "udd['selfie_camera_mp'] = udd['selfie_camera_mp'].fillna(median_selfie_camera_mp_by_year) # fill missing values in selfie_camera_mp with the median selfie_camera_mp for its respective release year\n",
        "udd['int_memory'] =  udd['int_memory'].fillna(median_int_memory_by_year)                  # fill missing values in int_memory with the median int_memory for its respective release year\n",
        "udd['ram'] = udd['ram'].fillna(median_ram_by_year)                                        # fill missing values in ram with the median ram for its respective release year\n",
        "udd['battery'] = udd['battery'].fillna(median_battery_by_year)                            # fill missing values in battery with the median battery for its respective release year\n",
        "udd['weight'] = udd['weight'].fillna(median_weight_by_year)                               # fill missing values in weight with the median weight for its respective release year"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NgRCpkBunhtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "udd.isnull().sum()"
      ],
      "metadata": {
        "id": "a1WDPZCHqQrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- the existence of outliers suggests that using the median value is a better method than using the mean for imputing missing values\n",
        "\n",
        "- we are making the assumption that the median value for missing values in each column can be used to replace missing values without significantly impacting the data"
      ],
      "metadata": {
        "id": "XvvSzYb5ocGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "xdjaOQ1g_KMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "udd['phone_age'] = 2021 - udd['release_year'] #calculating the age of the phone"
      ],
      "metadata": {
        "id": "U33FmD4U_cbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "udd.tail()"
      ],
      "metadata": {
        "id": "ISg3SjGW_12R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "udd['phone_age'].value_counts()"
      ],
      "metadata": {
        "id": "m-hwisJ8AUH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "udd['phone_age'].describe()"
      ],
      "metadata": {
        "id": "OsKo9XzjAkC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- on average, the phones in this data set are 5 years old\n",
        "- all used phones on this dataset are at least 1 year old, and 277 in this dataset are 1 year old\n",
        "- the oldest phones in the dataset are 8 years old, of which ther are 570"
      ],
      "metadata": {
        "id": "lZwSse6iAmfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outlier Detection"
      ],
      "metadata": {
        "id": "NHccW3Qs_Rkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "udd_numerical = udd.select_dtypes(include=[np.number]) #selecting numerical columns"
      ],
      "metadata": {
        "id": "AEEEnlYcBEBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in udd_numerical:\n",
        "  sns.boxplot(x=udd[col])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "vGGEwhDXCJi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- there are many outliers in the data\n",
        "- no outliers appear to be data entry mistakes, therefore we will not remove them"
      ],
      "metadata": {
        "id": "RX_SbvKhPnTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Data"
      ],
      "metadata": {
        "id": "Xnd_Y7A2_RwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lcDTGi9EZ1M"
      },
      "outputs": [],
      "source": [
        "x = udd.drop(['normalized_used_price','release_year'], axis=1) #independent variables\n",
        "y = udd['normalized_used_price']                #dependent variable\n",
        "\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "n-EfaPZB5hAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = sm.add_constant(x) #adding a constant to the independent variables"
      ],
      "metadata": {
        "id": "LlGCtBAu50Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.get_dummies(x, columns=x.select_dtypes(include=[\"object\", \"category\"]).columns.tolist(), drop_first=True)  # one hot encoding the categorical variables\n",
        "x.head()"
      ],
      "metadata": {
        "id": "L80ty_155_N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.astype(float) #converting the data type of the independent variables to float\n",
        "x.head()"
      ],
      "metadata": {
        "id": "eRW0xyc-6w22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) #splitting the data into train and test sets\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "S61gPRju7JFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- there are 2417 rows in the training data\n",
        "- there are 1037 rows in the test data\n",
        "- both test and train data have 50 columns"
      ],
      "metadata": {
        "id": "pWeTppWV6WBp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtLZofElx0v_"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It is a good idea to explore the data once again after manipulating it."
      ],
      "metadata": {
        "id": "ZkYW8xGS5xdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Brand Name"
      ],
      "metadata": {
        "id": "z9clXuDXx0v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.xticks(rotation=45)\n",
        "sns.countplot(x=udd['brand_name'])"
      ],
      "metadata": {
        "id": "JS5XDhgVx0v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- Samsung, Huawei and unnamed other brands are the most common brands in the dataset\n"
      ],
      "metadata": {
        "id": "anb6RQa2Ja1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Screen Size"
      ],
      "metadata": {
        "id": "4ujtS6rSx0wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['screen_size'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qXP-_D5fx0wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- There are many outliers in screensize, a possible explanation for this could be small numbers of flip phones and extra large tablets exist in the data\n",
        "\n",
        "- Not accounting for outliers, ~100% of the screen sizes in the dataset lie between 10 cm and about 17 cm"
      ],
      "metadata": {
        "id": "FmT9cCr2x0wA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Camera Megapixels"
      ],
      "metadata": {
        "id": "7YFFIEzVx0wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd_with_missing_values['main_camera_mp'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7GeAYvMZLQTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['main_camera_mp'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PyBnzXDULK3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- main camera mp had the most missing values in the original data\n",
        "- the distribution of main camera mp has not changed significantly after processing the data and imputing missing variables\n",
        "- 75% of the devices in the data set have between about 5mp and 25mp"
      ],
      "metadata": {
        "id": "6ff6BCj8x0wA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selfie Camera Megapixels"
      ],
      "metadata": {
        "id": "PeJqhfIQx0wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd_with_missing_values['selfie_camera_mp'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U6abqHIVL73x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['selfie_camera_mp'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wXHle0KGL-VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- selfie camera mp had only 2 values missing in the original data\n",
        "- the distribution of selfie camera mp has not changed discernably after processing the data and imputing missing variables\n",
        "- about 75% of the devices in the dataset have between about 2mp to 16mp selfie cameras\n",
        "- selfie cameras tend to be lower in resolution than main cameras for devices in this dataset"
      ],
      "metadata": {
        "id": "hQQlWLtiME-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Internal Memory"
      ],
      "metadata": {
        "id": "Fnxj4RPix0wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd_with_missing_values['int_memory']) #boxplot of internal memory from original dataset\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "efFY2MOdMhEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['int_memory']) #boxplot of internal memory from processed dataset\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qkn5JfgvMw58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- internal memory had only 4 values missing in the original data\n",
        "- the distribution of internal memory has not changed discernably after processing the data and imputing missing variables\n",
        "- not including outliers, nearly 100% of the devices in the dataset have less than 200 gb of memory"
      ],
      "metadata": {
        "id": "L8jQ4gt5x0wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ram"
      ],
      "metadata": {
        "id": "ZH9aSYGnx0wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd_with_missing_values['ram']) #box plot of ram from original dataset\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wFS-Zt0uNCwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['ram']) #boxplot of ram from processed data set\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "povNO8-UNFsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- Ram had only 4 values missing in the original data\n",
        "- the distribution of Ram has not changed discernably after processing the data and imputing missing variables\n",
        "- not including outliers, nearly 100% of used devices in this data have 4gb of ram"
      ],
      "metadata": {
        "id": "olJoKs1Jx0wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Battery"
      ],
      "metadata": {
        "id": "_VUrr52Ox0wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd_with_missing_values['battery']) #boxplot of battery from original dataset\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UqmvM_CAOXNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['battery']) #boxplot of battery from processed dataset\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wXuNN0EXOaTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- battery had only 6 values missing in the original data\n",
        "- the distribution of battery has not changed discernably after processing the data and imputing missing variables\n",
        "- 50% of devices in the dataset have between 2000 and 4000 mAh of capacity\n",
        "- less than 25% of the devices in the dataset have 'large' batteries as defined above"
      ],
      "metadata": {
        "id": "aB7m6rCnx0wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight"
      ],
      "metadata": {
        "id": "Na-4GkB5O_6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd_with_missing_values['weight']) #boxplot of weight from original dataset\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y4KW7xWwPNJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['weight']) #boxplot of weight from the processed dataset\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E7iF44nGPPgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- weight had only 7 values missing in the original data\n",
        "- the distribution of weight has not changed discernably after processing the data and imputing missing variables\n",
        "- Weight has a lot of outliers on the larger end of the distribution.\n",
        "- most of the used devices in the dataset weigh between about 90 to 250 grams"
      ],
      "metadata": {
        "id": "GamiKOZuPF7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phone Age"
      ],
      "metadata": {
        "id": "tKPyRWgyPuKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['phone_age'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "46HFSXHwQNKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- phones range from 1 to 8 years old in the dataset, with 50% of the used devices being 3-7 years old"
      ],
      "metadata": {
        "id": "Nn33ynWCQSU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Days Used"
      ],
      "metadata": {
        "id": "CD58couTPwcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=udd['days_used'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tqvZhEKvQjgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "- 50% of the devices in the dataset have been used between about 550 and 850 dayus"
      ],
      "metadata": {
        "id": "qZlZ8zL-Ql5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivariate analysis"
      ],
      "metadata": {
        "id": "p8v1rhlTRMqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalized New Price and Normalize Used Price"
      ],
      "metadata": {
        "id": "QVGvjLMWP62I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=udd['normalized_new_price'], y=udd['normalized_used_price'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1wVzeRjFQ5-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- there seems to be a linear relationship between normalized used price and normalized new price"
      ],
      "metadata": {
        "id": "Qudd7Es52vQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalized used price and phone age"
      ],
      "metadata": {
        "id": "2O5WcS0U24j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(x=udd['phone_age'], y=udd['normalized_used_price'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wi6hqlZS23oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- Normalized used price seems to decline gradually for the first 3 years of a phones age, and then decrease more sharply after 3 years"
      ],
      "metadata": {
        "id": "xLWlCmFJ3L-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heatmap\n"
      ],
      "metadata": {
        "id": "kR4w1bdK3ejH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "heatmap_columns = udd.select_dtypes(include=[np.number]).columns                  #list of numerical columns\n",
        "heatmap_columns = heatmap_columns.drop('release_year')                            #dropping release year as this is more of a categorical variable\n",
        "sns.heatmap(data=udd[heatmap_columns].corr(), annot=True, vmin=-1, vmax=1);       #heatmap of numerical values\n"
      ],
      "metadata": {
        "id": "ZMFc9bIn3oJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- The strongest positive correlations exist between battery and weight and screen size\n",
        "- the strongest negative correlations exist between selfie camera mp and phone age, and between days used and selfie camera mp, suggesting newer phones tend to have higher selfie camera mp and the mp of selfie cameras is more strongly affected by phone age than main camera mp."
      ],
      "metadata": {
        "id": "FnMRgnun4ytJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeUzI1OB4rqM"
      },
      "source": [
        "## Model Building - Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNRiMg0wMKth"
      },
      "outputs": [],
      "source": [
        "olsmodel = sm.OLS(y_train, x_train).fit()\n",
        "print(olsmodel.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- R-squared and Adjusted R squared can explain 84.5% and 84.1% of the variance in normalized used price of devices\n",
        "\n",
        "- the model is not underfitting the data"
      ],
      "metadata": {
        "id": "OHjymFWy8sj5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvoU3F6oMKti"
      },
      "source": [
        "## Model Performance Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3e6gzxdMKti"
      },
      "outputs": [],
      "source": [
        "def adj_r2_score(predictors, targets, predictions):                # function for finding adjusted R squared\n",
        "    r2 = r2_score(targets, predictions)\n",
        "    n = predictors.shape[0]\n",
        "    k = predictors.shape[1]\n",
        "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
        "\n",
        "\n",
        "def mape_score(targets, predictions):                               #function for finding MAPE\n",
        "    return np.mean(np.abs(targets - predictions) / targets) * 100\n",
        "\n",
        "def model_performance_regression(model, predictors, target):        #function for finding values to check model performance\n",
        "\n",
        "    pred = model.predict(predictors)                                # predicting using the independent variables\n",
        "\n",
        "    r2 = r2_score(target, pred)                                     # find R-squared\n",
        "    adjr2 = adj_r2_score(predictors, target, pred)                  # find djusted R-squared\n",
        "    rmse = np.sqrt(mean_squared_error(target, pred))                # find MSE\n",
        "    mae = mean_absolute_error(target, pred)                         # find MAE\n",
        "    mape = mape_score(target, pred)                                 # find MAPE\n",
        "\n",
        "    df_perf = pd.DataFrame({\"RMSE\": rmse,\"MAE\": mae,\"R-squared\": r2,\"Adj. R-squared\": adjr2,\"MAPE\": mape,},index=[0],) #creating a dataframe of the metrics\n",
        "\n",
        "    return df_perf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Performance\\n\")\n",
        "olsmodel_train_perf = model_performance_regression(olsmodel, x_train, y_train) # checking model performance on train set (seen 70% data)\n",
        "olsmodel_train_perf"
      ],
      "metadata": {
        "id": "6mA8BMQU_KXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Performance\\n\")\n",
        "olsmodel_test_perf = model_performance_regression(olsmodel, x_test, y_test) # checking model performance on test set (seen 30% data)\n",
        "olsmodel_test_perf"
      ],
      "metadata": {
        "id": "hQGHAme2Cw7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- the R2 is .84 for the training data, so the model is not underfitting\n",
        "- the RMSE and MAE of the training and test data are very close, so the model is not overfitting\n",
        "- MAPE value of 4.5 on the test data suggests that the model is able to predict within 4.5% error of the normalized used phone price"
      ],
      "metadata": {
        "id": "h9FO2xQ_C_Cp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9GxSQf-qH8e"
      },
      "source": [
        "## Checking Linear Regression Assumptions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In order to make statistical inferences from a linear regression model, it is important to ensure that the assumptions of linear regression are satisfied."
      ],
      "metadata": {
        "id": "UdGv3pQF50xP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be checking the following Linear Regression assumptions:\n",
        "\n",
        "1. No Multicollinearity\n",
        "\n",
        "2. Linearity of variables\n",
        "\n",
        "3. Independence of error terms\n",
        "\n",
        "4. Normality of error terms\n",
        "\n",
        "5. No Heteroscedasticity"
      ],
      "metadata": {
        "id": "1PTkVhdZFN7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "TEST FOR MULTICOLLINEARITY:\n",
        "\n",
        "Multicollinearity occurs when predictor variables in a regression model are correlated. This correlation is a problem because predictor variables should be independent. If the correlation between variables is high, it can cause problems when we fit the model and interpret the results. When we have multicollinearity in the linear model, the coefficients that the model suggests are unreliable.\n",
        "\n",
        "There are different ways of detecting (or testing) multicollinearity. One such way is by using the Variance Inflation Factor, or VIF.\n",
        "\n",
        "Variance Inflation Factor (VIF): Variance inflation factors measure the inflation in the variances of the regression parameter estimates due to collinearities that exist among the predictors. It is a measure of how much the variance of the estimated regression coefficient  βk  is \"inflated\" by the existence of correlation among the predictor variables in the model.\n",
        "\n",
        "- If VIF is 1, then there is no correlation among the  k th predictor and the remaining predictor variables, and hence, the variance of  βk  is not inflated at all.\n",
        "General Rule of thumb:\n",
        "\n",
        "- If VIF is between 1 and 5, then there is low multicollinearity.\n",
        "- If VIF is between 5 and 10, we say there is moderate multicollinearity.\n",
        "- If VIF is exceeding 10, it shows signs of high multicollinearity."
      ],
      "metadata": {
        "id": "qsd6Wy5MD9J1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multicollinearity"
      ],
      "metadata": {
        "id": "nQfIsq55FFwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def find_vif(predictors, exclude_prefixes=['brand_name','os']):\n",
        "  if exclude_prefixes:\n",
        "    columns_to_include = [col for col in predictors.columns if not any(col.startswith(prefix) for prefix in exclude_prefixes)] #exclude dummy variables by checking column names\n",
        "    predictors = predictors[columns_to_include]\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"feature\"] = predictors.columns\n",
        "\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(predictors.values, i)for i in range(len(predictors.columns))]                       #calculating VIF for each variable\n",
        "\n",
        "    return vif"
      ],
      "metadata": {
        "id": "POJ1Nkh8FJA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naX-iXItqH-b"
      },
      "outputs": [],
      "source": [
        "find_vif(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- We will be ignoring the VIF for dummy variables\n",
        "- The variables showing multicolinearity greater than 5 are screen size and weight. These variables show moderate multicollinearity.\n",
        "  - this follows logically with the correlation we saw on our heatmap in EDA"
      ],
      "metadata": {
        "id": "gZCvUopOXilp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To remove multicollinearity\n",
        "\n",
        "- Drop every column one by one that has a VIF score greater than 5.\n",
        "- Look at the adjusted R-squared and RMSE of all these models.\n",
        "- Drop the variable that makes the least change in adjusted R-squared.\n",
        "- Check the VIF scores again.\n",
        "- Continue till you get all VIF scores under 5."
      ],
      "metadata": {
        "id": "R2PDshEdEqCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def treating_multicollinearity(predictors, target, high_vif_columns):\n",
        "\n",
        "    adj_r2 = []                                                                 # empty lists to store adj. R-squared and RMSE values\n",
        "    rmse = []\n",
        "\n",
        "    for cols in high_vif_columns:                                               # iterating through the high VIF columns\n",
        "        train = predictors.loc[:, ~predictors.columns.str.startswith(cols)]\n",
        "        olsmodel = sm.OLS(target, train).fit()\n",
        "        adj_r2.append(olsmodel.rsquared_adj)                                    # appending adj. R-squared and RMSE values to their respective lists\n",
        "        rmse.append(np.sqrt(olsmodel.mse_resid))\n",
        "\n",
        "    temp = pd.DataFrame({\"col\": high_vif_columns,\"Adj. R-squared after_drop col\": adj_r2,\"RMSE after drop col\": rmse,}).sort_values(by=\"Adj. R-squared after_drop col\", ascending=False) #creating a dataframe for the results\n",
        "    temp.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return temp"
      ],
      "metadata": {
        "id": "gIaYx7SBE4_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moderate_vif_col_list = ['screen size','weight'] #creating a list of the columns with a moderate vif\n",
        "\n",
        "treated = treating_multicollinearity(x_train, y_train, moderate_vif_col_list)\n",
        "treated"
      ],
      "metadata": {
        "id": "HSvuf1zVGnBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train2 = x_train.loc[:, x_train.columns != 'screen_size'] #x train column without screen size\n",
        "x_test2 = x_test.loc[:, x_test.columns != 'screen_size']    #x test column without screen size\n",
        "\n",
        "vif= find_vif(x_train2)\n",
        "vif"
      ],
      "metadata": {
        "id": "0eUOonO0Hupn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- we have resolved problematic multicollinearity in the data as no values have a VIF > 5"
      ],
      "metadata": {
        "id": "5S2Qv4qGK4ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dealing with high p-value variables"
      ],
      "metadata": {
        "id": "NLF3AbYA0vuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Some of the dummy variables in the data have p-value > 0.05. So, they are not significant and we'll drop them\n",
        "- Sometimes p-values change after dropping a variable. So, we'll not drop all variables at once\n",
        "- Instead, we will do the following:\n",
        "  - Build a model, check the p-values of the variables, and drop the column with the highest p-value\n",
        "  - Create a new model without the dropped feature, check the p-values of the variables, and drop the column with the highest p-value\n",
        "  - Repeat the above two steps till there are no columns with p-value > 0.05"
      ],
      "metadata": {
        "id": "9YjPN7-aMOon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictors = x_train2.copy()                    #copying x_train2\n",
        "udd_cols = predictors.columns.tolist()\n",
        "\n",
        "max_p_value = 1                                 # setting an initial max p-value\n",
        "\n",
        "while len(udd_cols) > 0:                        # iterating through the columns\n",
        "    x_train_aux = predictors[udd_cols]          # defining the train set\n",
        "    model = sm.OLS(y_train, x_train_aux).fit()  # fitting the model\n",
        "\n",
        "    p_values = model.pvalues                    # getting the p-values and the maximum p-value\n",
        "    max_p_value = max(p_values)\n",
        "\n",
        "    feature_with_p_max = p_values.idxmax()      # name of the variable with maximum p-value\n",
        "\n",
        "    if max_p_value > 0.05:\n",
        "        udd_cols.remove(feature_with_p_max)\n",
        "    else:\n",
        "        break\n",
        "low_P_val_cols = udd_cols\n",
        "print(low_P_val_cols)"
      ],
      "metadata": {
        "id": "Pg0CSVakMjrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train3 = x_train2[low_P_val_cols]\n",
        "x_test3 = x_test2[low_P_val_cols]\n",
        "\n",
        "olsmod2 = sm.OLS(y_train, x_train3).fit()\n",
        "print(olsmod2.summary())"
      ],
      "metadata": {
        "id": "Ud8hwuW2Py1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Performance\\n\")                                               # checking model performance on train set (seen 70% data)\n",
        "olsmod2_train_perf = model_performance_regression(olsmod2, x_train3, y_train)\n",
        "olsmod2_train_perf"
      ],
      "metadata": {
        "id": "2M9NPFGiQOcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Performance\\n\")                                                    # checking model performance on test set (seen 30% data)\n",
        "olsmod2_test_perf = model_performance_regression(olsmod2, x_test3, y_test)\n",
        "olsmod2_test_perf"
      ],
      "metadata": {
        "id": "Dr0RQGUiQWcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- Dropping variables with high p values has not made the model perform worse\n",
        "- These values are very close to the first performance on train and test data"
      ],
      "metadata": {
        "id": "5F0RmS_JQa6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linearity and Independence"
      ],
      "metadata": {
        "id": "1L9xXYECRB3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We will test for linearity and independence by plotting fitted values vs residuals and look for patterns in the data with the following conclusions\n",
        "  - no pattern: model is linear and residuals are independent\n",
        "  - discernable pattern: model is non-linear and residuals are not independent\n"
      ],
      "metadata": {
        "id": "lU5Tc1LB9Cbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "udd_pred = pd.DataFrame() #creating a new dataframe\n",
        "\n",
        "udd_pred[\"Actual Values\"] = y_train                # actual values\n",
        "udd_pred[\"Fitted Values\"] = olsmod2.fittedvalues   # predicted values\n",
        "udd_pred[\"Residuals\"] = olsmod2.resid              # residuals\n",
        "\n",
        "udd_pred.head()"
      ],
      "metadata": {
        "id": "Abf96RZVRRzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.residplot(data=udd_pred, x=\"Fitted Values\", y=\"Residuals\", color=\"purple\", lowess=True)\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Fitted vs Residual plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rLH7-upc-1wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- there is no discernable pattern to the data above, therefore the assumptions of linearity and independence are satisfied\n"
      ],
      "metadata": {
        "id": "A8A-JNbr_AqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test for Normality"
      ],
      "metadata": {
        "id": "fabNlt3W_oHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The test for normality can be conduicted by checking the shape of the distribution of residuals, using a Q-Q plot of residuals, and using a Shapiro-Wilk test\n",
        "- We are looking for a normal distribution plot for the residuals, a straight line for the Q-Q plot, and a P-value of greater than .05 for the Shapiro-Wilk test"
      ],
      "metadata": {
        "id": "XM_MGOo-_zVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data=udd_pred, x=\"Residuals\", kde=True)\n",
        "plt.title(\"Normality of residuals\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jUhEKOS9AhS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pylab\n",
        "import scipy.stats as stats\n",
        "\n",
        "stats.probplot(udd_pred[\"Residuals\"], dist=\"norm\", plot=pylab)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_3ldaS1vAoGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.shapiro(udd_pred[\"Residuals\"])"
      ],
      "metadata": {
        "id": "BEaUkUDlAu5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- there is a bell shape to the residuals plot, but it is not perfectly normal\n",
        "- the tails of the residuals are strictly non-normal, but follow a straight line closer to the middle\n",
        "-the p-value is less than .05, so the residuals are not normal\n",
        "\n",
        "- overall, the residuals are not perfectly normal, but they can be approxmiated to be normal"
      ],
      "metadata": {
        "id": "x70Evju8A4y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homoscedasticity"
      ],
      "metadata": {
        "id": "TfU-bTclBc4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The test for homoscedasticity is done with the goldfeldquandt test\n",
        "- a P value greater than .05 means the residuals are homoscedastic"
      ],
      "metadata": {
        "id": "qJcQXrDRBjEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.compat import lzip\n",
        "\n",
        "name = [\"F statistic\", \"p-value\"]\n",
        "test = sms.het_goldfeldquandt(udd_pred[\"Residuals\"], x_train3)\n",
        "lzip(name, test)"
      ],
      "metadata": {
        "id": "eq6uQcsgCF8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- with a p value greater than .05, we can say the residuals are homoscedastic"
      ],
      "metadata": {
        "id": "lfbHFfGkCLx3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRYSDgFZMKtm"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_Sqvs4TMKtn"
      },
      "outputs": [],
      "source": [
        "x_train_final = x_train3.copy()\n",
        "x_test_final = x_test3.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "olsmodel_final = sm.OLS(y_train, x_train_final).fit()\n",
        "print(olsmodel_final.summary())"
      ],
      "metadata": {
        "id": "cGxnaxXmCbnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Performance\\n\")\n",
        "olsmodel_final_train_perf = model_performance_regression(olsmodel_final, x_train_final, y_train) # checking model performance on train set (seen 70% data)\n",
        "olsmodel_final_train_perf"
      ],
      "metadata": {
        "id": "-YaaIv7kCgc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test Performance\\n\")\n",
        "olsmodel_final_test_perf = model_performance_regression(olsmodel_final, x_test_final, y_test) # checking model performance on test set (seen 30% data)\n",
        "olsmodel_final_test_perf"
      ],
      "metadata": {
        "id": "hFV-75KpCs1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "- this model is able to explain ~83% of the variation in the data\n",
        "- the train and test RMSE and MAE are low and comparable, so our model is not suffering from overfitting\n",
        "- The MAPE suggests we can predict within 4.5% of the normalized used price of a device\n",
        "- the most significant variables for predicuting normalized used price are:\n",
        "  - main camera mp\n",
        "  - selfie camera mp\n",
        "  - ram\n",
        "  - weight\n",
        "  - normalized new price of the same device\n",
        "  - phone age\n",
        "  - 4g capability (and likely 5g too)"
      ],
      "metadata": {
        "id": "nsbXTSf1C289"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BkZh6eHluZK"
      },
      "source": [
        "## Actionable Insights and Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh_zkgqs4rqN"
      },
      "source": [
        "- ReCell should use this model to help determine the normalized used price they should use for their phones\n",
        "\n",
        "- ReCell should incentivize users to sell used devices that are not that old, and have higher camera mp, and are expensive when purchased new\n",
        "\n",
        "- ReCell could focus on different segments of users that value high ram and care about the weight of the phone they are buying\n",
        "\n",
        "- ReCell could offer some promotions to encourage consumers looking to buy a new phone to sell their phone to ReCell. This will possibly allow ReCell to gain more devices for resale.\n",
        "\n",
        "- ReCell should try to gather additional data for analysis usch as customer demographics to help determine if focusing on consumers or businesses looking to buy used phones presents the greatest opportunity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N-0Hj3aWFpYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWXXovuh4rqN"
      },
      "source": [
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "v_-uuGqH-qTt",
        "xxhpZv9y-qTw",
        "UvpMDcaaMKtI",
        "F6lrLPGCtun-",
        "GDhrW5F3tzE1",
        "93nR8KqUtziK",
        "yasG9p-Ltzuq",
        "qGu1-R8wt0BA",
        "MR8_UCZQvIuk",
        "vfwZ-qsPt0Ib",
        "xdjaOQ1g_KMB",
        "NHccW3Qs_Rkp",
        "Xnd_Y7A2_RwT",
        "z9clXuDXx0v_",
        "4ujtS6rSx0wA",
        "7YFFIEzVx0wA",
        "PeJqhfIQx0wA",
        "Fnxj4RPix0wB",
        "ZH9aSYGnx0wB",
        "_VUrr52Ox0wC",
        "Na-4GkB5O_6s",
        "tKPyRWgyPuKk",
        "CD58couTPwcc"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}